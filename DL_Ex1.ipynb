{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Percepton First exercise Panagiotis Tamvakidis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras as kr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense, Dropout, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data & Normalization\n",
    "After some tries I came with the result that I had to normalize the data after splitting them into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (29400, 784)\n",
      "y_train shape (29400,)\n",
      "X_test shape (12600, 784)\n",
      "y_test shape (12600,)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('./digit_recognizer_dataset.csv', sep=',')\n",
    "label = dataset.iloc[:,0]\n",
    "\n",
    "features =  dataset.iloc[:,1:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.30)\n",
    "\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# normalize to range 0-1\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "# return normalized images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Part of the exercise\n",
    "In this part is implemented the structure of the model as described in the given specs.\n",
    "The model was built with one hidden layer and with relu activation.\n",
    "The input shape (784) is calculated from the pixels from the length and width 28x28 =784.\n",
    "The number of epochs and batch as long as the shapes of the layers and the activation functions were specified according to the given specs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_part(X_train, X_test, y_train, y_test):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(10, input_shape=(784,)))\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "        model.add(Dense(10))\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(Dense(10))\n",
    "        model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "\n",
    "        batch_size = 64\n",
    "        model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.1),\n",
    "                      loss=\"sparse_categorical_crossentropy\",\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        model.fit(X_train,y_train, batch_size=batch_size, epochs=10)\n",
    "\n",
    "\n",
    "\n",
    "        loss, accuracy = model.evaluate(X_test,y_test)\n",
    "        print(\"Accuracy for the starting part \",accuracy)\n",
    "        return (loss, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Part Of the exercise\n",
    "In this part of the exercise there many changes in the structure of the model:\n",
    "\n",
    "\n",
    "    -A new hidden layer has added\n",
    "    -The batch size now is 16 \n",
    "    -The input and the hidden layers now have more units (1024 ,512)\n",
    "    -For keras implementation the glorot_uniform (Xavier) weight initiallizer is the default. \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_part(X_train, X_test, y_train, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_shape=(784,)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "    model.add(Dense(512,kernel_initializer=\"glorot_uniform\"))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(512,kernel_initializer=\"glorot_uniform\"))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(10,kernel_initializer=\"glorot_uniform\"))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    batch_size = 64\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.1),\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=16)\n",
    "\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(\"Accuracy for the Hyperparameter part \", accuracy)\n",
    "    return (loss,accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying the results of the first part of the exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "29400/29400 [==============================] - 1s 48us/step - loss: 0.9174 - accuracy: 0.7084\n",
      "Epoch 2/10\n",
      "29400/29400 [==============================] - 1s 48us/step - loss: 0.3496 - accuracy: 0.8951\n",
      "Epoch 3/10\n",
      "29400/29400 [==============================] - 1s 48us/step - loss: 0.3010 - accuracy: 0.9108\n",
      "Epoch 4/10\n",
      "29400/29400 [==============================] - 1s 46us/step - loss: 0.2763 - accuracy: 0.9175\n",
      "Epoch 5/10\n",
      "29400/29400 [==============================] - 1s 48us/step - loss: 0.2579 - accuracy: 0.9222\n",
      "Epoch 6/10\n",
      "29400/29400 [==============================] - 1s 47us/step - loss: 0.2482 - accuracy: 0.9250\n",
      "Epoch 7/10\n",
      "29400/29400 [==============================] - 1s 47us/step - loss: 0.2356 - accuracy: 0.9297\n",
      "Epoch 8/10\n",
      "29400/29400 [==============================] - 1s 48us/step - loss: 0.2257 - accuracy: 0.9331\n",
      "Epoch 9/10\n",
      "29400/29400 [==============================] - 1s 47us/step - loss: 0.2211 - accuracy: 0.9336\n",
      "Epoch 10/10\n",
      "29400/29400 [==============================] - 2s 57us/step - loss: 0.2146 - accuracy: 0.9350\n",
      "12600/12600 [==============================] - 0s 29us/step\n",
      "Accuracy for the starting part  0.9128571152687073\n",
      "======== Before =======\n",
      "Loss  0.29204423164564464 & Accuracy  0.9128571152687073\n"
     ]
    }
   ],
   "source": [
    "bef_loss, bef_acc =  first_part(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print('======== Before =======')\n",
    "print('Loss ',bef_loss ,'& Accuracy ', bef_acc )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying the results of the second part of the exercise\n",
    "Afte the specific modifications of the model that described above, the accuracy of the model reaches much better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "29400/29400 [==============================] - 10s 346us/step - loss: 0.4109 - accuracy: 0.8796\n",
      "Epoch 2/16\n",
      "29400/29400 [==============================] - 10s 336us/step - loss: 0.1539 - accuracy: 0.9547\n",
      "Epoch 3/16\n",
      "29400/29400 [==============================] - 10s 337us/step - loss: 0.1016 - accuracy: 0.9699\n",
      "Epoch 4/16\n",
      "29400/29400 [==============================] - 10s 339us/step - loss: 0.0718 - accuracy: 0.9787\n",
      "Epoch 5/16\n",
      "29400/29400 [==============================] - 10s 340us/step - loss: 0.0502 - accuracy: 0.9855\n",
      "Epoch 6/16\n",
      "29400/29400 [==============================] - 10s 351us/step - loss: 0.0378 - accuracy: 0.9886s - loss: 0.0379 - accuracy: \n",
      "Epoch 7/16\n",
      "29400/29400 [==============================] - 12s 408us/step - loss: 0.0253 - accuracy: 0.9935\n",
      "Epoch 8/16\n",
      "29400/29400 [==============================] - 11s 388us/step - loss: 0.0178 - accuracy: 0.9957\n",
      "Epoch 9/16\n",
      "29400/29400 [==============================] - 11s 371us/step - loss: 0.0113 - accuracy: 0.9981\n",
      "Epoch 10/16\n",
      "29400/29400 [==============================] - 10s 348us/step - loss: 0.0069 - accuracy: 0.9991\n",
      "Epoch 11/16\n",
      "29400/29400 [==============================] - 10s 337us/step - loss: 0.0045 - accuracy: 0.9995\n",
      "Epoch 12/16\n",
      "29400/29400 [==============================] - 10s 342us/step - loss: 0.0029 - accuracy: 0.9999\n",
      "Epoch 13/16\n",
      "29400/29400 [==============================] - 10s 339us/step - loss: 0.0023 - accuracy: 0.9999\n",
      "Epoch 14/16\n",
      "29400/29400 [==============================] - 10s 339us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 15/16\n",
      "29400/29400 [==============================] - 10s 341us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 16/16\n",
      "29400/29400 [==============================] - 10s 349us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "12600/12600 [==============================] - 3s 225us/step\n",
      "Accuracy for the Hyperparameter part  0.976190447807312\n",
      "======== After Parameter Tuning =======\n",
      "Loss  0.09925108399959133 & Accuracy  0.976190447807312\n"
     ]
    }
   ],
   "source": [
    "hyp_loss, hyp_acc = second_part(X_train, X_test, y_train, y_test)\n",
    "print('======== After Parameter Tuning =======')\n",
    "print('Loss ',hyp_loss ,'& Accuracy ', hyp_acc )\n",
    "# plt.plot(history.hyp_acc['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
